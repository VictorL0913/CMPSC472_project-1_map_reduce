{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPP3dOzCqxdTZrz8qKVE+xV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictorL0913/CMPSC472_project-1_map_reduce/blob/main/472_project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNOy6whF2fDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4748f398-50a9-4eab-d08d-d3f146ad9ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing parallel_sort_thread.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile parallel_sort_thread.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <pthread.h>\n",
        "#include <time.h>\n",
        "\n",
        "int *arr;\n",
        "int n, workers;\n",
        "\n",
        "// Compare function for qsort\n",
        "int cmp(const void *a, const void *b){\n",
        "    int x = *(int*)a, y = *(int*)b;\n",
        "    return (x>y) - (x<y);\n",
        "}\n",
        "\n",
        "// Merge two sorted subarrays into one - reduce phase\n",
        "void merge(int *a,int l1,int r1,int l2,int r2,int *tmp){\n",
        "    int i=l1,j=l2,k=0;\n",
        "    while(i<=r1 && j<=r2) tmp[k++] = (a[i]<=a[j]?a[i++]:a[j++]);\n",
        "    while(i<=r1) tmp[k++] = a[i++];\n",
        "    while(j<=r2) tmp[k++] = a[j++];\n",
        "    for(i=0;i<k;i++) a[l1+i]=tmp[i];\n",
        "}\n",
        "\n",
        "// Function run by each thread to sort its chunk - map phase\n",
        "void *thread_sort(void *arg){\n",
        "    long id=(long)arg;\n",
        "    int chunk=(n+workers-1)/workers;\n",
        "    int l=id*chunk;\n",
        "    if(l>=n) return NULL;\n",
        "    int r=l+chunk-1; if(r>=n) r=n-1;\n",
        "    qsort(arr+l,r-l+1,sizeof(int),cmp);\n",
        "    return NULL;\n",
        "}\n",
        "\n",
        "int main(int argc,char **argv){\n",
        "    if(argc<3){\n",
        "        printf(\"Usage: %s <size> <workers>\\n\",argv[0]);\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    n=atoi(argv[1]);\n",
        "    workers=atoi(argv[2]);\n",
        "    arr=malloc(n*sizeof(int));\n",
        "    srand(42);\n",
        "    for(int i=0;i<n;i++) arr[i]=rand();\n",
        "\n",
        "    pthread_t th[workers];\n",
        "    struct timespec t0,t1;\n",
        "    clock_gettime(CLOCK_MONOTONIC,&t0);\n",
        "\n",
        "    for(long i=0;i<workers;i++) pthread_create(&th[i],NULL,thread_sort,(void*)i);\n",
        "    for(int i=0;i<workers;i++) pthread_join(th[i],NULL);\n",
        "\n",
        "    clock_gettime(CLOCK_MONOTONIC,&t1);\n",
        "\n",
        "    int *tmp=malloc(n*sizeof(int)); // temp buffer for merging\n",
        "    int active=workers;\n",
        "    int chunk=(n+workers-1)/workers;\n",
        "\n",
        "    while(active>1){\n",
        "        int pairs=active/2;\n",
        "        for(int p=0;p<pairs;p++){\n",
        "            int l1=p*2*chunk, r1=l1+chunk-1; if(r1>=n) r1=n-1;\n",
        "            int l2=l1+chunk, r2=l2+chunk-1; if(r2>=n) r2=n-1;\n",
        "            merge(arr,l1,r1,l2,r2,tmp); // merge adjacent chunks\n",
        "        }\n",
        "        active=(active+1)/2; // halve the number of active threads\n",
        "        chunk*=2; // chunk size doubles after each iteration\n",
        "    }\n",
        "\n",
        "    // get evaluation metrics\n",
        "    double time_ms=(t1.tv_sec-t0.tv_sec)*1000.0 + (t1.tv_nsec-t0.tv_nsec)/1000000.0;\n",
        "    size_t mem_bytes = n*sizeof(int) + n*sizeof(int);\n",
        "    double mem_MB = mem_bytes / (1024.0*1024.0);\n",
        "\n",
        "    printf(\"workers: %d\\n\",workers);\n",
        "    printf(\"time: %.3f ms\\n\",time_ms);\n",
        "    printf(\"memory usage: %.6f MB\\n\",mem_MB);\n",
        "\n",
        "    free(tmp); free(arr);\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc parallel_sort_thread.c -pthread -o p1_threads\n",
        "!./p1_threads 32 1\n",
        "!./p1_threads 32 2\n",
        "!./p1_threads 32 4\n",
        "!./p1_threads 32 8\n",
        "!./p1_threads 131072 1\n",
        "!./p1_threads 131072 2\n",
        "!./p1_threads 131072 4\n",
        "!./p1_threads 131072 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAn3HRMVF0tL",
        "outputId": "b7a02b00-a146-4979-8b65-a2458c2758a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "workers: 1\n",
            "time: 0.129 ms\n",
            "memory usage: 0.000244 MB\n",
            "workers: 2\n",
            "time: 0.151 ms\n",
            "memory usage: 0.000244 MB\n",
            "workers: 4\n",
            "time: 0.430 ms\n",
            "memory usage: 0.000244 MB\n",
            "workers: 8\n",
            "time: 0.718 ms\n",
            "memory usage: 0.000244 MB\n",
            "workers: 1\n",
            "time: 27.215 ms\n",
            "memory usage: 1.000000 MB\n",
            "workers: 2\n",
            "time: 17.983 ms\n",
            "memory usage: 1.000000 MB\n",
            "workers: 4\n",
            "time: 16.814 ms\n",
            "memory usage: 1.000000 MB\n",
            "workers: 8\n",
            "time: 16.797 ms\n",
            "memory usage: 1.000000 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile parallel_sort_processes.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <unistd.h>\n",
        "#include <sys/mman.h> // used for shared memory for IPC\n",
        "#include <sys/wait.h>\n",
        "#include <time.h>\n",
        "\n",
        "// Compare function for qsort\n",
        "int cmp(const void *a,const void *b){\n",
        "    int x=*(int*)a, y=*(int*)b;\n",
        "    return (x>y)-(x<y);\n",
        "}\n",
        "\n",
        "int main(int argc,char **argv){\n",
        "    if(argc<3){\n",
        "        printf(\"Usage: %s <size> <workers>\\n\",argv[0]);\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    int n=atoi(argv[1]), workers=atoi(argv[2]);\n",
        "    // create shared memory for array so all processes can see same array\n",
        "    int *arr=mmap(NULL,n*sizeof(int),PROT_READ|PROT_WRITE,MAP_SHARED|MAP_ANONYMOUS,-1,0);\n",
        "    srand(42);\n",
        "    for(int i=0;i<n;i++) arr[i]=rand();\n",
        "\n",
        "    struct timespec t0,t1;\n",
        "    clock_gettime(CLOCK_MONOTONIC,&t0); // start timestamp\n",
        "\n",
        "    // Fork workers to sort their chunks - map phase\n",
        "    for(int i=0;i<workers;i++){\n",
        "        pid_t pid=fork();\n",
        "        if(pid==0){\n",
        "            int chunk=(n+workers-1)/workers;\n",
        "            int l=i*chunk, r=l+chunk-1; if(r>=n) r=n-1; if(l>=n) _exit(0);\n",
        "            qsort(arr+l,r-l+1,sizeof(int),cmp);\n",
        "            _exit(0);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Wait for all children to finish sorting\n",
        "    for(int i=0;i<workers;i++) wait(NULL);\n",
        "\n",
        "    clock_gettime(CLOCK_MONOTONIC,&t1); // end timestamp\n",
        "\n",
        "    // Merge sorted chunks - reduce phase\n",
        "    int *tmp = malloc(n*sizeof(int));\n",
        "    int active=workers;\n",
        "    int chunk=(n+workers-1)/workers;\n",
        "\n",
        "    while(active>1){\n",
        "        int pairs=active/2;\n",
        "        for(int p=0;p<pairs;p++){\n",
        "            int l1=p*2*chunk, r1=l1+chunk-1; if(r1>=n) r1=n-1; // left and right index of first chunk\n",
        "            int l2=l1+chunk, r2=l2+chunk-1; if(r2>=n) r2=n-1;  // left and right index of second chunk\n",
        "\n",
        "            // 2 pointer merge to sort the two chunks like merge sort\n",
        "            int i=l1,j=l2,k=0;\n",
        "            while(i<=r1 && j<=r2) tmp[k++] = (arr[i]<=arr[j]?arr[i++]:arr[j++]);\n",
        "            while(i<=r1) tmp[k++] = arr[i++];\n",
        "            while(j<=r2) tmp[k++] = arr[j++];\n",
        "            for(i=0;i<k;i++) arr[l1+i]=tmp[i];\n",
        "        }\n",
        "        // after each pass, the number of active processes is halved\n",
        "        active=(active+1)/2;\n",
        "        // chunk size is doubled\n",
        "        chunk*=2;\n",
        "    }\n",
        "\n",
        "    // get evaluation metrics\n",
        "    double time_ms=(t1.tv_sec-t0.tv_sec)*1000.0 + (t1.tv_nsec-t0.tv_nsec)/1000000.0;\n",
        "    size_t mem_bytes = n*sizeof(int) + n*sizeof(int);\n",
        "    double mem_MB = mem_bytes/(1024.0*1024.0);\n",
        "\n",
        "    printf(\"workers: %d\\n\",workers);\n",
        "    printf(\"time: %.3f ms\\n\",time_ms);\n",
        "    printf(\"memory usage: %.6f MB\\n\",mem_MB);\n",
        "\n",
        "    free(tmp);\n",
        "    munmap(arr,n*sizeof(int));\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYQQN369Qo5u",
        "outputId": "f5c13c8d-9419-4e50-a298-bf9a24126460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing parallel_sort_processes.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc parallel_sort_processes.c -o p1_process\n",
        "!./p1_process 32 1\n",
        "!./p1_process 32 2\n",
        "!./p1_process 32 4\n",
        "!./p1_process 32 8\n",
        "!./p1_process 131072 1\n",
        "!./p1_process 131072 2\n",
        "!./p1_process 131072 4\n",
        "!./p1_process 131072 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXTk-EmpQxqM",
        "outputId": "ee55d540-ba96-48da-818c-b3975236512a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "workers: 1\n",
            "time: 0.268 ms\n",
            "memory usage: 0.000244 MB\n",
            "workers: 2\n",
            "time: 1.759 ms\n",
            "memory usage: 0.000244 MB\n",
            "workers: 4\n",
            "time: 1.465 ms\n",
            "memory usage: 0.000244 MB\n",
            "workers: 8\n",
            "time: 1.862 ms\n",
            "memory usage: 0.000244 MB\n",
            "workers: 1\n",
            "time: 27.617 ms\n",
            "memory usage: 1.000000 MB\n",
            "workers: 2\n",
            "time: 17.273 ms\n",
            "memory usage: 1.000000 MB\n",
            "workers: 4\n",
            "time: 17.168 ms\n",
            "memory usage: 1.000000 MB\n",
            "workers: 8\n",
            "time: 19.217 ms\n",
            "memory usage: 1.000000 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile maxagg_thread.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <pthread.h>\n",
        "#include <time.h>\n",
        "\n",
        "int *arr;             // main array\n",
        "int n, workers;       // array size and number of threads\n",
        "int global_max;       // shared max value\n",
        "pthread_mutex_t lock; // mutex for synchronization\n",
        "\n",
        "// Function for each thread to compute local max and update global max\n",
        "void *thread_max(void *arg){\n",
        "    long id = (long)arg;\n",
        "    int chunk = (n + workers - 1) / workers;\n",
        "    int l = id * chunk;\n",
        "    if(l >= n) return NULL;\n",
        "    int r = l + chunk - 1; if(r >= n) r = n - 1;\n",
        "    int local_max = arr[l];\n",
        "    for(int i = l+1; i <= r; i++) if(arr[i] > local_max) local_max = arr[i];\n",
        "\n",
        "    pthread_mutex_lock(&lock);           // lock before updating global max\n",
        "    if(local_max > global_max) global_max = local_max;\n",
        "    pthread_mutex_unlock(&lock);         // unlock\n",
        "    return NULL;\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv){\n",
        "    if(argc < 3){\n",
        "        printf(\"Usage: %s <size> <workers>\\n\", argv[0]);\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    n = atoi(argv[1]);\n",
        "    workers = atoi(argv[2]);\n",
        "    arr = malloc(n * sizeof(int));\n",
        "    srand(42);\n",
        "    for(int i=0;i<n;i++) arr[i]=rand();\n",
        "\n",
        "    global_max = arr[0];\n",
        "    pthread_mutex_init(&lock, NULL);\n",
        "\n",
        "    pthread_t th[workers];\n",
        "    struct timespec t0, t1;\n",
        "    clock_gettime(CLOCK_MONOTONIC, &t0);\n",
        "\n",
        "    // create threads - map phase\n",
        "    for(long i=0;i<workers;i++) pthread_create(&th[i], NULL, thread_max, (void*)i);\n",
        "    for(int i=0;i<workers;i++) pthread_join(th[i], NULL);\n",
        "\n",
        "    clock_gettime(CLOCK_MONOTONIC, &t1);\n",
        "\n",
        "    double time_ms = (t1.tv_sec - t0.tv_sec)*1000.0 + (t1.tv_nsec - t0.tv_nsec)/1000000.0;\n",
        "    size_t mem_bytes = n*sizeof(int) + sizeof(int);\n",
        "    double mem_MB = mem_bytes / (1024.0*1024.0);\n",
        "\n",
        "    // get evaluation metrics - reduce phase\n",
        "    printf(\"workers: %d\\n\", workers);\n",
        "    printf(\"max value: %d\\n\", global_max);\n",
        "    printf(\"time: %.3f ms\\n\", time_ms);\n",
        "    printf(\"memory usage: %.6f MB\\n\", mem_MB);\n",
        "\n",
        "    free(arr);\n",
        "    pthread_mutex_destroy(&lock);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8r8HzY2a-ar",
        "outputId": "77f3a93b-c281-4aab-e43f-f2ad5d0d186c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting maxagg_thread.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc maxagg_thread.c -pthread -o p2_threads\n",
        "!./p2_threads 32 1\n",
        "!./p2_threads 32 2\n",
        "!./p2_threads 32 4\n",
        "!./p2_threads 32 8\n",
        "!./p2_threads 131072 1\n",
        "!./p2_threads 131072 2\n",
        "!./p2_threads 131072 4\n",
        "!./p2_threads 131072 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e20UFgQ2byNG",
        "outputId": "81f76824-75aa-4e41-8b1c-f2cada682fc5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "workers: 1\n",
            "max value: 2108313867\n",
            "time: 0.233 ms\n",
            "memory usage: 0.000126 MB\n",
            "workers: 2\n",
            "max value: 2108313867\n",
            "time: 0.967 ms\n",
            "memory usage: 0.000126 MB\n",
            "workers: 4\n",
            "max value: 2108313867\n",
            "time: 0.277 ms\n",
            "memory usage: 0.000126 MB\n",
            "workers: 8\n",
            "max value: 2108313867\n",
            "time: 0.425 ms\n",
            "memory usage: 0.000126 MB\n",
            "workers: 1\n",
            "max value: 2147476004\n",
            "time: 0.671 ms\n",
            "memory usage: 0.500004 MB\n",
            "workers: 2\n",
            "max value: 2147476004\n",
            "time: 0.482 ms\n",
            "memory usage: 0.500004 MB\n",
            "workers: 4\n",
            "max value: 2147476004\n",
            "time: 0.538 ms\n",
            "memory usage: 0.500004 MB\n",
            "workers: 8\n",
            "max value: 2147476004\n",
            "time: 0.760 ms\n",
            "memory usage: 0.500004 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile maxagg_process.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <unistd.h>\n",
        "#include <sys/mman.h>\n",
        "#include <sys/wait.h>\n",
        "#include <pthread.h>\n",
        "#include <time.h>\n",
        "\n",
        "\n",
        "int main(int argc, char **argv){\n",
        "    if(argc < 3){\n",
        "        printf(\"Usage: %s <size> <workers>\\n\", argv[0]);\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    int n = atoi(argv[1]);\n",
        "    int workers = atoi(argv[2]);\n",
        "\n",
        "    // array of random numbers (local memory)\n",
        "    int *arr = malloc(n * sizeof(int));\n",
        "    srand(42);\n",
        "    for(int i=0;i<n;i++) arr[i] = rand();\n",
        "\n",
        "    // Shared memory for global max\n",
        "    int *global_max = mmap(NULL, sizeof(int), PROT_READ|PROT_WRITE,\n",
        "                           MAP_SHARED|MAP_ANONYMOUS, -1, 0);\n",
        "    *global_max = arr[0];\n",
        "\n",
        "    // Shared mutex for synchronization across process\n",
        "    pthread_mutex_t *lock = mmap(NULL, sizeof(pthread_mutex_t),\n",
        "                                 PROT_READ|PROT_WRITE,\n",
        "                                 MAP_SHARED|MAP_ANONYMOUS, -1, 0);\n",
        "\n",
        "    pthread_mutexattr_t attr;\n",
        "    pthread_mutexattr_init(&attr);\n",
        "    pthread_mutexattr_setpshared(&attr, PTHREAD_PROCESS_SHARED);\n",
        "    pthread_mutex_init(lock, &attr);\n",
        "\n",
        "    struct timespec t0, t1;\n",
        "    clock_gettime(CLOCK_MONOTONIC, &t0);  // start timestamp\n",
        "\n",
        "    // Fork workers to compute local max and update global max\n",
        "    for(int i=0;i<workers;i++){\n",
        "        pid_t pid = fork();\n",
        "        if(pid == 0){\n",
        "            // Compute chunk boundaries\n",
        "            int chunk = (n + workers - 1) / workers;\n",
        "            int l = i * chunk;\n",
        "            int r = l + chunk - 1;\n",
        "            if(r >= n) r = n - 1;\n",
        "            if(l >= n) _exit(0);\n",
        "\n",
        "            // Local max computation\n",
        "            int local_max = arr[l];\n",
        "            for(int j = l + 1; j <= r; j++)\n",
        "                if(arr[j] > local_max) local_max = arr[j];\n",
        "\n",
        "            // Update global max with locking to ensure atomicity\n",
        "            pthread_mutex_lock(lock);\n",
        "            if(local_max > *global_max) *global_max = local_max;\n",
        "            pthread_mutex_unlock(lock);\n",
        "\n",
        "            _exit(0);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Wait for all children\n",
        "    for(int i=0;i<workers;i++) wait(NULL);\n",
        "    clock_gettime(CLOCK_MONOTONIC, &t1);  // end timestamp\n",
        "\n",
        "    // Get evaluation metrics\n",
        "    double time_ms = (t1.tv_sec - t0.tv_sec)*1000.0 +\n",
        "                     (t1.tv_nsec - t0.tv_nsec)/1000000.0;\n",
        "    size_t mem_bytes = n*sizeof(int) + sizeof(int);\n",
        "    double mem_MB = mem_bytes / (1024.0*1024.0);\n",
        "\n",
        "    // output\n",
        "    printf(\"workers: %d\\n\", workers);\n",
        "    printf(\"array size: %d\\n\", n);\n",
        "    printf(\"global max value: %d\\n\", *global_max);\n",
        "    printf(\"time: %.3f ms\\n\", time_ms);\n",
        "    printf(\"memory usage: %.6f MB\\n\", mem_MB);\n",
        "\n",
        "    free(arr);\n",
        "    pthread_mutex_destroy(lock);\n",
        "    munmap(global_max, sizeof(int));\n",
        "    munmap(lock, sizeof(pthread_mutex_t));\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDruEkANb3JH",
        "outputId": "88626764-a6f5-40f8-c1d1-7bb76886bb3f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting maxagg_process.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc maxagg_process.c -o p2_processes\n",
        "!./p2_processes 32 1\n",
        "!./p2_processes 32 2\n",
        "!./p2_processes 32 4\n",
        "!./p2_processes 32 8\n",
        "!./p2_processes 131072 1\n",
        "!./p2_processes 131072 2\n",
        "!./p2_processes 131072 4\n",
        "!./p2_processes 131072 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1zNqRLEb7-K",
        "outputId": "e35e72bb-5efd-46a3-d6f6-3f4358aa338a",
        "collapsed": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "workers: 1\n",
            "array size: 32\n",
            "global max value: 2108313867\n",
            "time: 0.399 ms\n",
            "memory usage: 0.000126 MB\n",
            "workers: 2\n",
            "array size: 32\n",
            "global max value: 2108313867\n",
            "time: 0.449 ms\n",
            "memory usage: 0.000126 MB\n",
            "workers: 4\n",
            "array size: 32\n",
            "global max value: 2108313867\n",
            "time: 1.153 ms\n",
            "memory usage: 0.000126 MB\n",
            "workers: 8\n",
            "array size: 32\n",
            "global max value: 2108313867\n",
            "time: 2.030 ms\n",
            "memory usage: 0.000126 MB\n",
            "workers: 1\n",
            "array size: 131072\n",
            "global max value: 2147476004\n",
            "time: 0.962 ms\n",
            "memory usage: 0.500004 MB\n",
            "workers: 2\n",
            "array size: 131072\n",
            "global max value: 2147476004\n",
            "time: 0.794 ms\n",
            "memory usage: 0.500004 MB\n",
            "workers: 4\n",
            "array size: 131072\n",
            "global max value: 2147476004\n",
            "time: 1.518 ms\n",
            "memory usage: 0.500004 MB\n",
            "workers: 8\n",
            "array size: 131072\n",
            "global max value: 2147476004\n",
            "time: 1.512 ms\n",
            "memory usage: 0.500004 MB\n"
          ]
        }
      ]
    }
  ]
}